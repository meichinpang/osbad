# Standard library
import json
import logging
import os
import pathlib
from pathlib import Path
from typing import Iterable, Literal, Mapping, Any

# ------------------------------------------------------------------------
# Update the config here depending on the data source
HP_DATA_SOURCE: Literal["tohoku", "severson"] = "severson"
"""
Active hyperparameter data source selection. Determines which
dataset-specific config is loaded throughout the pipeline.

.. important::

    Set ``HP_DATA_SOURCE`` to either ``tohoku`` or ``severson``
    depending on the dataset being analyzed. This selection controls
    which hyperparameter configuration is loaded from the
    ``machine_learning/hp_config_schema`` directory.
"""

# ------------------------------------------------------------------------
# Modify this global directory path for storing pipeline artifacts if needed.
PIPELINE_OUTPUT_DIR = Path.cwd().joinpath("artifacts_output_dir")
"""
Global directory path for storing pipeline artifacts.

All figures, plots, and intermediate artifacts generated by the pipeline
or Jupyter notebooks are written to this directory. If the directory does
not already exist, it will be created at runtime.

.. important::

    ``PIPELINE_OUTPUT_DIR`` defines the root location where all results
    (per-cell artifacts, exported plots, metrics, and hyperparameters)
    are stored. Ensure this path points to a valid writable location
    before running the pipeline.
"""

if not os.path.exists(PIPELINE_OUTPUT_DIR):
    os.mkdir(PIPELINE_OUTPUT_DIR)

def find_repo_root(marker: str = "pyproject.toml"):
    """
    Locate the root directory of the repository by searching for a marker file.

    This function starts from the current working directory and traverses
    upwards in the directory hierarchy until it finds a directory containing
    the specified marker file (default is "pyproject.toml"). If the marker
    file is not found, an exception is raised.

    Args:
        marker (str): The name of the marker file to search for. Default is
            "pyproject.toml".

    Returns:
        pathlib.Path: The path to the root directory of the repository.

    Raises:
        FileNotFoundError: If the marker file is not found in any parent
            directories up to the filesystem root.
    """
    current_path = Path(__file__).resolve()

    for parent in current_path.parents:
        if (parent / marker).exists():
            return parent
    raise FileNotFoundError(
        f"Marker file '{marker}' not found in any parent directories.")

# Define the root directory of the repository
ROOT_DIR = find_repo_root()
# print(f"Root directory of the repository: {ROOT_DIR}")

# Path to the database directory
DB_DIR = ROOT_DIR.joinpath("database")
# print(f"DATABASE_DIRECTORY: {DB_DIR}")

# ------------------------------------------------------------------------
def artifacts_output_dir(selected_cell_label: str) -> pathlib.PosixPath:
    """
    Ensure and return the artifacts directory for a given cell.

    Creates (if missing) a per-cell subdirectory under
    ``PIPELINE_OUTPUT_DIR`` and returns its path. All figures and
    artifacts for the selected cell should be written to this location.

    Args:
        selected_cell_label (str): Identifier of the evaluated cell used
            to name the subdirectory.

    Returns:
        pathlib.PosixPath: Path to the cell-specific artifacts directory.
    """
    # create a new folder for each evaluated cell
    # store all figures output for each evaluated
    # cell into its corresponding folder
    selected_cell_artifacts_dir = PIPELINE_OUTPUT_DIR.joinpath(
        selected_cell_label)

    if not os.path.exists(selected_cell_artifacts_dir):
        os.mkdir(selected_cell_artifacts_dir)

    return selected_cell_artifacts_dir


def create_json_hp_config(
    output_json_filepath: str,
    hp_dict: dict):
    """
    Create and save a JSON file containing hyperparameter settings.

    This function writes a dictionary of hyperparameter configurations
    to a JSON file at the specified path.

    Args:
        output_json_filepath (str): Path to save the output JSON file.
        hp_dict (dict): Dictionary containing hyperparameter configurations
            with labeled keys.

    Returns:
        None: A JSON file is written to the specified location.

    Example:
        .. code-block::

            hp_schema_iforest = {
                "contamination": {"low": 0.0, "high": 0.5},
                "n_estimators": {"low": 100, "high": 500},
                "max_samples": {"low": 100, "high": total_cycle_count},
                "threshold": {"low": 0.0, "high": 1.0}
            }

            iforest_hp_config_filepath = (
                Path.cwd()
                .parent.parent.parent
                .joinpath(
                    "machine_learning",
                    "hp_config_schema",
                    "iforest_hp_config.json"))

            bconf.create_json_hp_config(
                iforest_hp_config_filepath,
                hp_dict=hp_schema_iforest)
    """
    with open(output_json_filepath, "wb") as fp:
        fp.write(json.dumps(
            hp_dict,
            ensure_ascii=False,
            indent="\n").encode("utf8"))

def load_json_hp_config(input_json_filepath: str) -> dict:
    """
    Load hyperparameter configuration from a JSON file.

    This function reads a JSON file containing hyperparameter configurations
    and returns the contents as a dictionary.

    Args:
        input_json_filepath (str): Path to the JSON file containing
            hyperparameter configuration.

    Returns:
        dict: Dictionary containing the loaded hyperparameter configurations.

    Example:
        .. code-block::

            iforest_hp_config_filepath = (
                Path(__file__)
                .parent.parent.parent
                .joinpath(
                    "machine_learning",
                    "hp_config_schema",
                    "iforest_hp_config.json"))

            bconf.load_json_hp_config(iforest_hp_config_filepath)
    """

    with open(input_json_filepath, "rb") as jp_json:
        hp_dict = json.load(jp_json)

    return hp_dict

# ----------------------------------------------------------------------------
# Path to ml_model_hp_config:
# machine_learning/hp_config_schema/
# {data_source}_hp_config/{model}_hp_config.json

def load_model_hp_configs(
    models: Iterable[str],
    data_source: str,
    schema_base_dir: Path | None = None,
) -> Mapping[str, Any]:
    """
    Load hyperparameter JSON configs for the given models from a specific
    data source.

    Args:
        models : iterable of str
            Model names (e.g., "iforest", "knn", "gmm", ...).
        data_source : str
            Subdirectory under hp_config_schema
            ("tohoku_hp_config", "severson_hp_config").
        schema_base_dir : Path or None
            Base directory containing the 'machine_learning/hp_config_schema'
            folder. Defaults to three levels up from this file.

    Returns:
        dict[str, Any]
            Mapping of model name.
    """
    current_config_filepath = Path(__file__).resolve()

    if schema_base_dir is None:
        repo_root = current_config_filepath.parents[2]
        schema_base_dir = repo_root.joinpath(
            "machine_learning", "hp_config_schema")

    # Build full schema directory path for this data source
    schema_dir = schema_base_dir.joinpath(f"{data_source}_hp_config")

    configs: dict[str, Any] = {}
    for model in models:
        json_path = schema_dir.joinpath(f"{model}_hp_config.json")
        configs[model] = load_json_hp_config(json_path)
    return configs

models = ["iforest", "knn", "gmm", "lof", "pca", "autoencoder"]

# Hyperparameter configuration for severson dataset -------------------------

# Load configs for the "severson" dataset
severson_hp_configs = load_model_hp_configs(models, data_source="severson")
"""
Hyperparameter config selection for the Severson dataset. Preloads
per-model configs from the schema for repeated access for different models.
"""

# Access specific configs for severson dataset
_iforest_hp_config_severson  = severson_hp_configs["iforest"]
_knn_hp_config_severson = severson_hp_configs["knn"]
_gmm_hp_config_severson = severson_hp_configs["gmm"]
_lof_hp_config_severson = severson_hp_configs["lof"]
_pca_hp_config_severson = severson_hp_configs["pca"]
_autoencoder_hp_config_severson = severson_hp_configs["autoencoder"]

# Hyperparameter configuration for tohoku dataset -------------------------
# Load configs for the "tohoku" dataset
tohoku_hp_configs = load_model_hp_configs(models, data_source="tohoku")
"""
Hyperparameter config selection for the Tohoku dataset. Preloads
per-model configs from the schema for repeated access for different models.
"""

# Access individual configs for hyperparameters:
_iforest_hp_config_tohoku = tohoku_hp_configs["iforest"]
_knn_hp_config_tohoku = tohoku_hp_configs["knn"]
_gmm_hp_config_tohoku = tohoku_hp_configs["gmm"]
_lof_hp_config_tohoku = tohoku_hp_configs["lof"]
_pca_hp_config_tohoku = tohoku_hp_configs["pca"]
_autoencoder_hp_config_tohoku = tohoku_hp_configs["autoencoder"]

# ----------------------------------------------------------------------------
class CustomFormatter(logging.Formatter):
    """
    Custom logging formatter with colorized output.

    This formatter applies ANSI escape codes to add colors for different
    logging levels and customizes the format string for messages. INFO
    messages are displayed as plain text, while DEBUG, WARNING, ERROR, and
    CRITICAL messages include timestamps, file names, and line numbers for
    better context.

    Logging level styles:
        - INFO: Grey text, message only.
        - DEBUG: Red text with timestamp, name, file, and line number.
        - WARNING: Bold red text with extended debug-style format.
        - ERROR: Bold red text with extended debug-style format.
        - CRITICAL: Bold red text with extended debug-style format.
    """
    # https://talyian.github.io/ansicolors/
    # orange = "\x1b[38;5;215m"
    # darkred = "\x1b[38;5;1m"
    grey = "\x1b[38;21m"
    yellow = "\x1b[33;21m"
    red = "\x1b[31;21m"
    bold_red = "\x1b[31;1m"
    reset = "\x1b[0m"
    debug_format = ("%(asctime)s - %(name)s - %(levelname)s"
            + "\n%(message)s (%(filename)s:%(lineno)d)")
    info_format = "%(message)s"

    # Logging levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
    FORMATS = {
        logging.INFO: grey + info_format,
        logging.DEBUG: red + debug_format + reset,
        logging.WARNING: bold_red + debug_format + reset,
        logging.ERROR: bold_red + debug_format + reset,
        logging.CRITICAL: bold_red + debug_format + reset
    }

    def format(self, record):
        log_fmt = self.FORMATS.get(record.levelno)
        formatter = logging.Formatter(log_fmt)
        return formatter.format(record)